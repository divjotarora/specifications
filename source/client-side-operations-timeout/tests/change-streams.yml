description: "timeoutMS behaves correctly for change streams"

schemaVersion: "1.2"

runOnRequirements:
  - minServerVersion: "4.4"
    topologies: ["replicaset", "sharded-replicaset"]

createEntities:
  - client:
      id: &failPointClient failPointClient
      useMultipleMongoses: false
  - client:
      id: &client client
      uriOptions:
        timeoutMS: 10
      useMultipleMongoses: false
      observeEvents:
        - commandStartedEvent
      # Drivers are not required to execute killCursors during resume attempts, so it should be ignored for command
      # monitoring assertions.
      ignoreCommandMonitoringEvents: ["killCursors"]
  - database:
      id: &database database
      client: *client
      databaseName: &databaseName test
  - collection:
      id: &collection collection
      database: *database
      collectionName: &collectionName coll

initialData:
  - collectionName: *collectionName
    databaseName: *databaseName
    documents: []

tests:
  - description: "error if maxAwaitTimeMS is greater than timeoutMS"
    operations:
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
          timeoutMS: 5
          maxAwaitTimeMS: 10
        expectError:
          isClientError: true

  - description: "error if maxAwaitTimeMS is equal to timeoutMS"
    operations:
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
          timeoutMS: 5
          maxAwaitTimeMS: 5
        expectError:
          isClientError: true

  - description: "timeoutMS applied to initial aggregate"
    operations:
      - name: failPoint
        object: testRunner
        arguments:
          client: *failPointClient
          failPoint:
            configureFailPoint: failCommand
            mode: { times: 1 }
            data:
              failCommands: ["aggregate"]
              blockConnection: true
              blockTimeMS: 15
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
        expectError:
          isTimeoutError: true
    expectEvents:
      - client: *client
        events:
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
  
  # If maxAwaitTimeMS is not set, timeoutMS should be refreshed for the getMore and the getMore should not have a
  # maxTimeMS field.
  - description: "timeoutMS is refreshed for getMore if maxAwaitTimeMS is not set"
    operations:
      - name: failPoint
        object: testRunner
        arguments:
          client: *failPointClient
          failPoint:
            configureFailPoint: failCommand
            mode: { times: 2 }
            data:
              failCommands: ["find", "getMore"]
              blockConnection: true
              blockTimeMS: 15
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
          timeoutMS: 20
        saveResultAsEntity: &changeStream changeStream
      - name: iterateOnce
        object: *changeStream
    expectEvents:
      - client: *client
        events:
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
          - commandStartedEvent:
              commandName: getMore
              databaseName: *databaseName
              command:
                getMore: { $$type: ["int", "long"] }
                collection: *collectionName
                maxTimeMS: { $$exists: false }

  # If maxAwaitTimeMS is set, timeoutMS should still be refreshed for the getMore and the getMore command should have a
  # maxTimeMS field.
  - description: "timeoutMS is refreshed for getMore if maxAwaitTimeMS is set"
    operations:
      - name: failPoint
        object: testRunner
        arguments:
          client: *failPointClient
          failPoint:
            configureFailPoint: failCommand
            mode: { times: 2 }
            data:
              failCommands: ["find", "getMore"]
              blockConnection: true
              blockTimeMS: 15
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
          timeoutMS: 20
          batchSize: 2
          maxAwaitTimeMS: 1
        saveResultAsEntity: &changeStream changeStream
      - name: iterateOnce
        object: *changeStream
    expectEvents:
      - client: *client
        events:
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
          - commandStartedEvent:
              commandName: getMore
              databaseName: *databaseName
              command:
                getMore: { $$type: ["int", "long"] }
                collection: *collectionName
                maxTimeMS: 1

  # The timeout should be applied to the entire resume attempt, not individually to each command. The test creates a
  # change stream with timeoutMS=20 which returns an empty initial batch and then sets a fail point to block both
  # getMore and aggregate for 12ms each and fail with a resumable error. When the resume attempt happens, the getMore
  # and aggregate block for longer than 20ms total, so it times out.
  - description: "timeoutMS applies to full resume attempt in a next call"
    operations:
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
          timeoutMS: 20
        saveResultAsEntity: &changeStream changeStream
      - name: failPoint
        object: testRunner
        arguments:
          client: *failPointClient
          failPoint:
            configureFailPoint: failCommand
            mode: { times: 2 }
            data:
              failCommands: ["getMore", "aggregate"]
              blockConnection: true
              blockTimeMS: 12
              errorCode: 7 # HostNotFound - resumable but does not require an SDAM state change.
      - name: iterateUntilDocumentOrError
        object: *changeStream
        expectError:
          isTimeoutError: true
    expectEvents:
      - client: *client
        events:
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
          - commandStartedEvent:
              commandName: getMore
              databaseName: *databaseName
              command:
                getMore: { $$type: ["int", "long"] }
                collection: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }

  - description: "change stream can be iterated again if previous iteration times out"
    operations:
      - name: createChangeStream
        object: *collection
        arguments:
          pipeline: []
        saveResultAsEntity: &changeStream changeStream
      # Block getMore for 15ms to force the next() call to time out.
      - name: failPoint
        object: testRunner
        arguments:
          client: *failPointClient
          failPoint:
            configureFailPoint: failCommand
            mode: { times: 1 }
            data:
              failCommands: ["getMore"]
              blockConnection: true
              blockTimeMS: 15
      # The original aggregate didn't return any events so this should do a getMore and return a timeout error.
      - name: iterateUntilDocumentOrError
        object: *changeStream
        expectError:
          isTimeoutError: true
      # The previous iteration attempt timed out so this should re-create the change stream.
      - name: iterateUntilDocumentOrError
        object: *changeStream
    expectEvents:
      - client: *client
        events:
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
          - commandStartedEvent:
              commandName: getMore
              databaseName: *databaseName
              command:
                getMore: { $$type: ["int", "long"] }
                collection: *collectionName
          - commandStartedEvent:
              commandName: aggregate
              databaseName: *databaseName
              command:
                aggregate: *collectionName
                maxTimeMS: { $$type: ["int", "long"] }
